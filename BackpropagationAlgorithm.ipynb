{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fad42e27-2a8f-438a-b3bb-cf1a57e0e6c5",
   "metadata": {},
   "source": [
    "# Backprogpagation Algorithm \n",
    "Backpropagation, or backward propagation of errors, is an algorithm that is designed to test for errors working back from output nodes to input nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350c0265-1d68-4ece-a86b-6e78be0e99bd",
   "metadata": {},
   "source": [
    "## Import modules\n",
    "- `numpy` for n-dim array processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5793619b-08dd-4e5a-9acf-b1d5f02bf22e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da66727-ae33-4786-bd91-ad6a7fbaf0ec",
   "metadata": {},
   "source": [
    "## Creating Dataset\n",
    "A sample data is created to be trained on by the Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e59aa00-5684-4344-a6d2-fccf4607bc8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [2, 9], \n",
    "    [1, 5], \n",
    "    [3, 9]\n",
    "])\n",
    "\n",
    "y = np.array([\n",
    "    [92], \n",
    "    [86], \n",
    "    [89]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ea358d-58d4-4362-9bd3-8e89230e486f",
   "metadata": {},
   "source": [
    "## Preprocessing Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73e017b9-092d-4e1a-b9a4-7fadd0b684ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n"
     ]
    }
   ],
   "source": [
    "train_x = X / np.amax(X, axis =0)\n",
    "train_y = y/100\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebdf469-71e9-443c-a6ef-1e08477bc4bf",
   "metadata": {},
   "source": [
    "## Defining the Neural Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5db583b6-9452-4809-b62d-c105e4e6348e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"A Basic Neural Network with single hidden layer\n",
    "    \n",
    "    Attributes:\n",
    "    ----------\n",
    "        w1 (ndarray): The weight matrix for input to hidden layer\n",
    "        w2 (ndarray): The weight matrix for hidden to output layer\n",
    "    \n",
    "    Methods:\n",
    "    -------\n",
    "        forward(X)\n",
    "            Performs forward propogation and return output\n",
    "            \n",
    "        backward(X, y, o)\n",
    "            Performs backward propogation and updates weights\n",
    "            \n",
    "        train(X, y)\n",
    "            Runs a single training step\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        ----\n",
    "            input_size (int): The number of input units\n",
    "            hidden_size (int): The number of hidden units\n",
    "            output_size (int): The number of output units\n",
    "        \"\"\"\n",
    "        np.random.seed(0) # To reproduce results\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.w1 = np.random.randn(self.input_size, self.hidden_size)\n",
    "        \n",
    "        self.w2 = np.random.randn(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"Performs forward propogation and return output\n",
    "        \n",
    "        Args:\n",
    "        ----\n",
    "            X (ndarray): Input for the model\n",
    "        Returns:\n",
    "        -------\n",
    "            o (ndarray): The final output of the model\n",
    "        \"\"\"\n",
    "        \n",
    "        self.z_in1 = np.dot(X, self.w1)\n",
    "        \n",
    "        self.z1 = self.sigmoid(self.z_in1)\n",
    "        \n",
    "        self.z2_in = np.dot(self.z1, self.w2)\n",
    "        \n",
    "        o = self.sigmoid(self.z2_in)\n",
    "        \n",
    "        return o\n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        \"\"\"Calculate the sigmoid activation\"\"\"\n",
    "        return 1./(1+ np.exp(-z))\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoidPrime(z):\n",
    "        \"\"\"Calculates the derivate of sigmoid activation\"\"\"\n",
    "        return z * (1 - z)\n",
    "        \n",
    "    def backward(self, X, y, o):\n",
    "        \"\"\"Performs backward propogation and updates weights\n",
    "        Args:\n",
    "        ----\n",
    "            X (ndarray): Input for the model\n",
    "            y (ndarray): Acutal Labels\n",
    "            o (ndarray): Estimated labels\n",
    "        \"\"\"\n",
    "        self.o_err = y - o\n",
    "        self.o_delta = self.o_err * self.sigmoidPrime(o) # Sigmoid' x = x * ( 1 - x)\n",
    "        \n",
    "        self.z_err = self.o_delta.dot(self.w2.T)\n",
    "        self.z_delta = self.z_err * self.sigmoidPrime(self.z1)\n",
    "        \n",
    "        self.w1 += X.T.dot(self.z_delta)\n",
    "        self.w2 += self.z_in1.T.dot(self.o_delta)\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        \"\"\"Performs backward propogation and updates weights\n",
    "        Args:\n",
    "        ----\n",
    "            X (ndarray): Input for the model\n",
    "            y (ndarray): Acutal Labels    \n",
    "        \n",
    "        \"\"\"\n",
    "        o = self.forward(X)\n",
    "        self.backward(X, y, o)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe8458e-1ff0-46b9-a547-007e6b74d4d6",
   "metadata": {},
   "source": [
    "## Training a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f029f885-275b-4bbf-887f-0e9ee64e40aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inital Weights\n",
      "W1:\n",
      " [[ 1.76405235  0.40015721  0.97873798]\n",
      " [ 2.2408932   1.86755799 -0.97727788]]\n",
      "W2:\n",
      " [[ 0.95008842]\n",
      " [-0.15135721]\n",
      " [-0.10321885]]\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(2, 3, 1)\n",
    "print(\"Inital Weights\")\n",
    "print(\"W1:\\n\", nn.w1)\n",
    "print(\"W2:\\n\", nn.w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc0c728c-fcac-499b-b1c8-bf1639ffd0a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Output:\n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output:\n",
      " [[0.90777362]\n",
      " [0.86397641]\n",
      " [0.89712377]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5000):\n",
    "    nn.train(train_x, train_y)\n",
    "    \n",
    "print('Actual Output:\\n', train_y)\n",
    "print('Predicted Output:\\n', nn.forward(train_x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
